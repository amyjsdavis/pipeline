---
title: "Get taxa from checklists"
author:
- Damiano Oldoni
- Peter Desmet
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    theme: yeti
    df_print: paged
knit: (function(input_file, encoding) { rmarkdown::render(input_file, encoding = encoding, output_file = paste0("../docs/",sub(".Rmd", ".html", basename(input_file))))})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load libraries

```{r}
library(rgbif)
library(trias)
library(purrr)
library(dplyr)
library(magrittr)
```

## Define checklist datasets

```{r}
checklist_datasets <- c(
  "9ff7d317-609b-4c08-bd86-3bc404b77c42", # uuid of first dataset
  "87e99777-7f54-4209-9688-cbf7a9179ebe" # uuid of second dataset
  )
```

Show dataset info:

```{r}
# Call to GBIF /datasets api
datasets_info <- purrr::map(checklist_datasets, function (x) datasets(uuid = x))

# Display table with:
# datasetKey, title of dataset, last modified, publishingOrganizationKey, doi
map_dfr(datasets_info, function(x) list(datasetKey = x$data$key, title = x$data$title, modified = x$data$modified, publisher = x$data$publishingOrganizationKey, doi = x$data$doi))
```


## Get taxa from checklists

```{r}
# Call to GBIF /species/search API, using datasets as input (paging implemented)
dataframes_taxonKeys <- checklists_import(checklist_datasets, tot_limit = NULL, 
                                          verbose = TRUE)
taxa <- map_dfr(dataframes_taxonKeys, function(x) list(key = x$data$key, dataset_scientificname = x$data$scientificName, datasetKey = x$data$datasetKey, nubKey = x$data$nubKey))
```


Show some stats:

```{r}
taxa %>%
  group_by(datasetKey) %>%
  summarize(
    taxa = n(),
    taxa_not_in_backbone = sum(is.na(nubKey))
  )
```

Total number of taxa:

```{r}
nrow(taxa)
```

Reorder by nubKey:

```{r}
taxa %<>% select(nubKey, key, dataset_scientificname, datasetKey) %>%
  arrange(nubKey)
```

Create vector of nubKeys:

```{r}
taxa %>%
  select(nubKey) %>%
  filter(!is.na(nubKey)) %>%
  distinct(nubKey) %>%
  pull(nubKey) -> nub_keys
```

Number of nubKeys:

```{r}
length(nub_keys)
```

## Get GBIF Backbone Taxonomy information:

```{r}
# Call to GBIF/species/nubKey to retrieve:
# scientificName
# kingdom
# taxonomicStatus
# acceptedKey (if available)
# accepted (if available)
gbif_terms = c("nubKey", "scientificName", "kingdom", "taxonomicStatus", "acceptedKey", "accepted")
taxa_backbone <- map_dfr(nub_keys, function(x) name_usage(key = x)$data) %>%
        select(gbif_terms)
```

Add  GBIF Backbone Taxonomy information to taxa:

```{r}
# add GBIF Backbone information to taxa with valid nubKey.
# bind rows if nubKey is NA ( that means NAs are added)
left_join(taxa %>% filter(!is.na(nubKey)), taxa_backbone, by = "nubKey") %>%
  bind_rows(taxa %>% filter(is.na(nubKey))) -> taxa
```

Preview taxa:

```{r}
head(taxa)
```

Save taxa to tsv file:

```{r}
file <- "../data/output/taxa.tsv"
write.table(taxa, file = file, append = FALSE, row.names = FALSE, col.names = TRUE, sep = "\t", quote = FALSE)
```
